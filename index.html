<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <title>Qianqian Jin's Website</title>
    <style>
      body { font-family: Arial, sans-serif; background-color: #f4f4f4; }
      nav { background-color: #333; color: #f4f4f4; padding: 10px; text-align: center; }
      nav a { color: #f4f4f4; margin: 0 10px; text-decoration: none; }
      nav a:hover { text-decoration: underline; }

      /* å›¾ç‰‡1æ ·å¼ */
      .image-one {
      float: right;
      margin: 20px;
      width: 150px;
      height: auto;
      border-radius: 33%;
      border: 3px solid #f4f4f4;
      box-shadow: 0 4px 4px rgba(0, 0, 0, 0.1);  
      margin-top: 0px;           /* é¡¶éƒ¨å¤–è¾¹è· */
        }

        .icon-list {
        float: right;
        margin-right: 10px;
        margin-top: 10px;
        /* display: flex; */
        gap: 1rem;
        list-style: none;
        }

      /* å›¾ç‰‡2æ ·å¼ */


        .left {
    width: 650px;    /* ç¬¬äºŒå¼ å›¾ç‰‡å®½åº¦ */
    height: auto;
    border-radius: 0%; /* å®Œå…¨åœ†å½¢ */
    border: 0px solid #f4f4f4;
    box-shadow: 0 4px 4px rgba(0, 0, 0, 0.2);
    margin-top: 5px;           /* é¡¶éƒ¨å¤–è¾¹è· */
    margin-bottom: 20px; /* ä¸‹è¾¹è· */
    margin-left: auto;   /* å·¦å³è‡ªåŠ¨åˆ†é…ç©ºé—´ */
    margin-right: auto;  /* å·¦å³è‡ªåŠ¨åˆ†é…ç©ºé—´ */
    display: block;      /* å¿…é¡»æ˜¯å—çº§å…ƒç´ æ‰èƒ½å±…ä¸­ */
}


      /* å›¾ç‰‡3æ ·å¼ */
      .center {
                display: block;         /* ä½¿å›¾ç‰‡æˆä¸ºå—çº§å…ƒç´  */
                margin: 5px auto;      /* ä¸Šä¸‹é—´è·ä¸º25pxï¼Œå·¦å³è‡ªåŠ¨å±…ä¸­ */
                width: 1250px;           /* å›¾ç‰‡å®½åº¦ */
                height: auto;           /* ä¿æŒåŸæ¯”ä¾‹ */
                border-radius: 5%;      /* æ— åœ†è§’ */
                border: 0px solid #f4f4f4;
                margin-bottom: 50px; /* ä¸‹è¾¹è· */
            }

    /* å›¾ç‰‡2æ ·å¼ */


        .right {
    width: 650px;    /* ç¬¬äºŒå¼ å›¾ç‰‡å®½åº¦ */
    height: auto;
    border-radius: 0%; /* å®Œå…¨åœ†å½¢ */
    border: 0px solid #f4f4f4;
    box-shadow: 0 4px 4px rgba(0, 0, 0, 0.2);
    margin-top: 5px;           /* é¡¶éƒ¨å¤–è¾¹è· */
    margin-bottom: 20px; /* ä¸‹è¾¹è· */
    margin-left: auto;   /* å·¦å³è‡ªåŠ¨åˆ†é…ç©ºé—´ */
    margin-right: auto;  /* å·¦å³è‡ªåŠ¨åˆ†é…ç©ºé—´ */
    display: block;      /* å¿…é¡»æ˜¯å—çº§å…ƒç´ æ‰èƒ½å±…ä¸­ */
}




        /* æ ‡é¢˜æ ·å¼ */
        h1 {
            text-align: center;         /* å±…ä¸­å¯¹é½ */
            font-size: 68px;            /* å­—ä½“å¤§å° */
            font-family: "Georgia", serif; /* å­—ä½“æ ·å¼ */
            color: #333;                /* å­—ä½“é¢œè‰² */
            font-weight: bold;          /* åŠ ç²— */
            margin-top: 10px;           /* é¡¶éƒ¨å¤–è¾¹è· */
            margin-bottom: 30px; /* ä¸‹è¾¹è· */

        }
        /* æ ‡é¢˜æ ·å¼ */
        p1 {
            text-align: center;         /* å±…ä¸­å¯¹é½ */
            font-size: 25px;            /* å­—ä½“å¤§å° */
            font-family: "Georgia", serif; /* å­—ä½“æ ·å¼ */
            color: #333;                /* å­—ä½“é¢œè‰² */
            font-weight: bold;          /* åŠ ç²— */
            margin-top: 20px;           /* é¡¶éƒ¨å¤–è¾¹è· */
            margin-bottom: 10px; 
            
        }
        p       {
                text-align: left;         /* å±…ä¸­å¯¹é½ */
                font-size: 18px;            /* å­—ä½“å¤§å° */
                font-family: "Georgia", serif; /* å­—ä½“æ ·å¼ */
                color: #333;                /* å­—ä½“é¢œè‰² */
                /* font-weight: bold;          åŠ ç²— */
                margin-top: 15px;           /* é¡¶éƒ¨å¤–è¾¹è· */
                margin-bottom: 20px; /* ä¸‹è¾¹è· */
                letter-spacing: 1px;       /* å­—ç¬¦é—´è· */
                line-height: 1.5;          /* è¡Œé«˜ */
                word-spacing: 1px;         /* å•è¯é—´è· */
                        /* text-align: justify;       ä¸¤ç«¯å¯¹é½ */

                }

    .text-box {
                width: 800px;           /* é™åˆ¶å®½åº¦ä¸º300åƒç´  */
                margin: 20px auto;      /* å±…ä¸­æ˜¾ç¤º */
                padding: 20px;          /* å†…è¾¹è· */
                font-size: 20px;            /* å­—ä½“å¤§å° */
                font-family: "Georgia", serif; /* å­—ä½“æ ·å¼ */
                line-height: 1.5;          /* è¡Œé«˜ */

                color: #000000;            /* æ–‡å­—é¢œè‰² */
                background-color: #f4f4f4;  /* èƒŒæ™¯é¢œè‰² */
                border: 0px solid #ccc; /* è¾¹æ¡† */
                border-radius: 2px;     /* åœ†è§’ */
                text-align: left;     /* æ–‡æœ¬å±…ä¸­ */
                word-wrap: break-word;  /* è‡ªåŠ¨æ¢è¡Œ */
                /* word-break: break-all;  å¼ºåˆ¶æ¢è¡Œï¼Œé¿å…æº¢å‡º */
                /* overflow: hidden;       éšè—è¶…å‡ºå†…å®¹ */
            }

    /* Flex å®¹å™¨ */
    .flex-container {
                display: flex;               /* ä½¿ç”¨ Flex å¸ƒå±€ */
                align-items: center;         /* å‚ç›´å±…ä¸­å¯¹é½ */
                gap: 20px;                   /* å›¾ç‰‡å’Œæ–‡æœ¬ä¹‹é—´çš„é—´è· */
                margin: 20px auto;           /* æ•´ä½“å±…ä¸­ */
                padding: 10px;
                background-color: #f4f4f4;   /* èƒŒæ™¯é¢œè‰² */
                border-radius: 8px;          /* åœ†è§’è¾¹æ¡† */
                /* box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); é˜´å½±æ•ˆæœ */
                margin-top: 20; /* ä¸‹è¾¹è· */
                margin-bottom: 20; /* ä¸‹è¾¹è· */
            }
    </style>


</head>

    <nav>
        <a href="#home">Home</a>
        <a href="#skills">Skills</a>
        <a href="#projects">Research Project</a>
        <a href="#contactme">Contact me</a>
    </nav>

  

      <div style="
      height: 450px;
      background-image: url('images/back2.png');  /* æ–°çš„èƒŒæ™¯å›¾ */
      background-size: cover;
      background-position: center;
      display: flex;
      align-items: center;
      justify-content: center;
      color: white;
      font-size: 32px;
    ">
      <h1>Welcome to Qianqian Jin's Portfolio</h1>
    </div>



    <div style="padding: 10px;padding-top: 30px;">
        <!-- æ’å…¥å›¾ç‰‡ -->
        <img src="images/qq.png" alt="ä¸ªäººç…§ç‰‡"class="image-one">
  


<section id="home">

      <!-- <p1>Brief description </p1> -->
      <p1>Brief description</p1>

        <p className="prose-sm text-stone-200 sm:prose-base lg:prose-lg">
            I am a Ph.D. in Civil Engineering from the University of Central Florida, 
            specializing in <strong className="text-stone-100"> Traffic Safety Research</strong>. <br> 
            Currently, I am <strong className="text-stone-100", style="font-size: large;">
              Open to Work.</strong>
        
        In my academic period, I expert in surrogate safety measures to 
        quantitatively assess conflict risks across diverse scenarios, 
        including adverse weather conditions, 
          unsignalized intersections and right-turning scenarios. 
        By leveraging statistical models and deep learning models based on traffic datasets, 
        I conducted a comprehensive conflict risk analysis and developed predictive models.
    </p>
<br>
<br>

    <ul style="display: flex; gap: 1rem; list-style: none; padding: 0; justify-content: flex-end; margin-right: 20px;">
<p style="font-family:Georgia, serif;"> Social  </p>
        <li>
          <a href="https://github.com/Daydayjin606" target="_blank">
            <img src="images/github-icon.png" alt="GitHub" width="40" />
          </a>
        </li>
        <li>
          <a href="https://www.linkedin.com/in/qianqian-jin-06b0ba257/" target="_blank">
            <img src="images/linkedin-icon.png" alt="LinkedIn" width="40" />
          </a>
        </li>
        <li>
          <a href="https://scholar.google.com/citations?user=8K8j7IsAAAAJ" target="_blank">
            <img src="images/googlescholar-icon.png" alt="Google Scholar" width="40" />
          </a>
        </li>
      </ul>



     <!-- å·¦å¯¹é½ -->
     <div class="clearfix">
      <img src="images/overview.png" alt="surrogate safety measures" class="center">
    </div>
    <p style="text-align: center;"> Figure 1 Roadmap of Traffic Safety Research Throughout My Academic Journey  </p>
</section>




<section id="skills">
     
    <p1>Skills &amp; Abilities</p1>
    <ul style="list-style: none; padding-left: 12px; line-height: 1.6; font-size: 2ch; margin-bottom: 3pc;">
      <li style="margin: 3px; font-family:Georgia, serif;"> âœ“  Programming Language: Python, R, SQL</li>       
      <li style="margin: 3px; font-family:Georgia, serif;"> âœ“  Machine Learning Frameworks: PyTorch, Scikit-learn</li>
      <li style="margin: 3px; font-family:Georgia, serif;"> âœ“  Modeling Techniques: Statistical Models, Machine Learning Model, Deep Learning Model</li>
      <li style="margin: 3px; font-family:Georgia, serif;"> âœ“  Engineering Techniques: CATIA, Inventor, MATLAB/Simulink, SiLAB </li>
    </ul>
    



<section id="projects">
    <p1 style='margin-top: 20px;'> Research & Projects</p1>

<!-- å·¦å¯¹é½ -->
<div class="clearfix">
    <div class="flex-container">

        <!-- å›¾ç‰‡ -->
        <img src="images/Picture7.png" alt="picture3" class="left">

        <!-- æ–‡æœ¬æ¡† -->
        <div class="text-box">
        - Understanding the scenarios based on Vision Language Model (Manuscript in preparation) <br>
        
        Developed a  <strong className="text-stone-100">conflict risk assessment framework</strong>  for intersections, 
        focusing on right-turn interactions between vehicles and vulnerable road users (VRUs). 
        The approach integrates the <strong className="text-stone-100">SigLIP 2 vision-language model</strong> with region-level captioning to 
        jointly understand visual scenes and classify conflict risk levels. This work enables automated, 
        <strong className="text-stone-100">real-time risk analysis </strong>and supports the deployment of smart safety systems.
            </div>

    </div>
    <p style="text-align: left;"> Figure 2 Conflict Risks Evaluation based on Vision Language Model  </p>

</div>





<!-- å³å¯¹é½ -->

<div class="clearfix">
  <div class="flex-container">
      <!-- æ–‡æœ¬æ¡† -->
      <div class="text-box">
              - Real-time traffic conflict detection by using deep learning method (Under review)<br>
         
          This study explores <strong className="text-stone-100">pedestrian-vehicle conflicts</strong> during right turns 
          at signalized intersections in right-hand traffic countries. 
          By combining <strong className="text-stone-100">268 crash reports</strong> and <strong className="text-stone-100">275 conflict cases</strong>, 
          the study emphasizes how analyzing conflict-related factors can serve as pre-crash indicators, 
          offering early warning signs that help prevent future crashes. 
          Conflict risks are quantitatively evaluated using PET and RTTC metrics, 
          with RTTC demonstrating superior predictive performanceâ€”thresholds were identified for Approach and Departure crosswalks. 
          The analysis identified four distinct interaction patterns shaped by crosswalk type and pedestrian movement direction. 

          </div>

          <!-- å›¾ç‰‡ -->
              <img src="images/ped.png" alt="picture3" class="right">

  </div>
  <p style="text-align: right;"> Figure 3 Interaction Patterns between Right-Turning Vehicles and Pedestrians at Signalized Intersections </p>

</div>










<!-- å·¦å¯¹é½ -->
<div class="clearfix">
    <div class="flex-container">
        <!-- å›¾ç‰‡ -->
        <img src="images/unsignalizedintersection.png" alt="unsignalizedintersection" class="left">

        <!-- æ–‡æœ¬æ¡† -->
        <div class="text-box">
            <a href="https://www.sciencedirect.com/science/article/abs/pii/S0001457525000296" target="_blank">
                - Assessing conflict likelihood and its severity at interconnected intersections: Insights from drone trajectory data (AAP)</a><br>

            Most studies analyzing crash factors at unsignalized intersections focus solely on the isolated intersection itself. 
            This study investigates how proximity to signalized intersections affects traffic conflicts at unsignalized intersections. 
            We utilized <strong className="text-stone-100">microscopic high-resolution trajectory dataset</strong> extracted from the CitySim drone dataset. 
            To represent real dangerous events, conflict probability and severity were introduced and assessed using two surrogate safety measures.
            A Structural Equation Model is applied to explore 
            the <strong className="text-stone-100">interactive relationship</strong> within the interconnected intersections. 
            

            </div>

    </div>
    <p style="text-align: left;"> Figure 4 Base Map of Interconnected Intersection  </p>

</div>


<!-- å³å¯¹é½ -->

<div class="clearfix">
    <div class="flex-container">
        <!-- æ–‡æœ¬æ¡† -->
        <div class="text-box">
            <a href="https://github.com/Daydayjin606/Conflict_detection" target="_blank">
                - Real-time traffic conflict detection by using deep learning method (Under review)</a><br>

            <strong className="text-stone-100">Real-time large-scale conflict estimation</strong> is still a challenge due to high efficiency requirement. 
            To tackle this challenge, we propose a novel approach leveraging deep learning models for real-time conflict detection. 
            We divided drone videos into sequential frames and  <strong className="text-stone-100">paired consecutive frames</strong> as input for deep neural networks. 
            Conflict events, estimated by conflict measures, are labeled as learning outputs. Time to collision (TTC) 
            is used as an alternative metric for conflict detection, and the data is processed by selecting 
            the minimum TTC within each frame to identify conflicting events. 
            Through training,  <strong className="text-stone-100">deep neural networks (ResNet-101)</strong> learn to detect conflict with paired frame image features. 
            The results on the testing set are promising, 
            achieving 91% detection accuracy, 84% precision, and 81% F1 score. 
            A key advantage of our approach lies in its efficiency during inference without trajectory processing, requiring only milliseconds.
            
            </div>

            <!-- å›¾ç‰‡ -->
                <img src="images/Picture1.png" alt="picture3" class="right">

    </div>
    <p style="text-align: right;"> Figure 5 Real-time Conflict Detection Models based on Drone Videos  </p>

</div>


<!-- å·¦å¯¹é½ -->
<div class="clearfix">
    <div class="flex-container">
        <!-- å›¾ç‰‡ -->
        <img src="images/weather.png" alt="weather" class="left">

        <!-- æ–‡æœ¬æ¡† -->
        <div class="text-box">
            <a href="https://journals.sagepub.com/doi/abs/10.1177/03611981241298683" target="_blank">
                - Identifying the Threshold Discrepancy of Rear-End Conflicts under Clear and Rainy Weather Conditions Using Trajectory Data (TRR)</a><br>

            Adverse weather conditions have been examined for their impact on safety events estimated from surrogate metrics, 
            however, limited research focuses on discrepancies in SSM thresholds under 
            <strong className="text-stone-100"> various weather characteristics </strong>
            This study investigated specific thresholds for different surroage safety measures under clear and light rainy weather conditions based on drone trajectory dataset. 
            The results indicate that thresholds of MTTC and DRAC metrics have statistically significant differences under two weather scenarios.
            These findings can inform the design of active safety systems and traffic safety policies 
            by suggesting different safety thresholds for triggering safety systems under clear and rainy conditions, 
            thereby reducing false alarms.


            </div>
    </div>
    <p style="text-align: left;"> Figure 6 Trajectory Drone Data under Different Weather Conditions  </p>

</div>


<!-- å³å¯¹é½ -->
<div class="clearfix">
    <div class="flex-container">
        <!-- æ–‡æœ¬æ¡† -->
        <div class="text-box">

            <a href="https://journals.sagepub.com/doi/abs/10.1177/03611981221121270" target="_blank">
                - Probabilistic Prediction of Collisions between Cyclists and Vehicles Based on Uncertainty of Cyclistsâ€™ Movements (TRR)</a><br>

                This study proposes <strong className="text-stone-100">a probabilistic method to assess collision risk</strong> between cyclists and vehicles by accounting 
                for the uncertainty in cyclistsâ€™ movements. 
                Using <strong className="text-stone-100">a first-order Markov model </strong>
                and <strong className="text-stone-100">Monte Carlo sampling</strong>, 
                the study estimates collision probabilities based on distributions of minimum distance and time-to-collision. 
                Compared to a traditional AEB system, the proposed model shows higher accuracy in predicting collision risk in real-world crash cases, 
                offering valuable insights for improving vehicle safety systems for cyclists.


            <strong className="text-stone-100"></strong>

            </div>

            <!-- å›¾ç‰‡ -->
                <img src="images/probability.png" alt="picture3" class="right">

    </div>

    <p style="text-align: right;"> Figure 7 Flowchart of quantitative estimation of collision risk between vehicles and vulnerable road users </p>

</div>




</section>


<section id="contactme">

    <h2>Contact me</h2>

    <p>If you have any questions, please feel free to contact me, Thank you !</p>

    <p style="text-align: left;">
        ğŸ“§ Email: 
        <a href="mailto:qianqianjin010@gmail.com">qianqianjin010@gmail.com</a>
      </p>

      <ul style="display: flex; gap: 3rem; list-style: none; padding: 0;">

        <li>
          <a href="https://github.com/Daydayjin606" target="_blank">
            <img src="images/github-icon.png" alt="GitHub" width="62" />
          </a>
        </li>
        <li>
          <a href="https://www.linkedin.com/in/qianqian-jin-06b0ba257/" target="_blank">
            <img src="images/linkedin-icon.png" alt="LinkedIn" width="62" />
          </a>
        </li>
        <li>
          <a href="https://scholar.google.com/citations?user=8K8j7IsAAAAJ" target="_blank">
            <img src="images/googlescholar-icon.png" alt="Google Scholar" width="62" />
          </a>
        </li>
      </ul>
  
  </section>




  <div style="
  height: 77px;
  background-image: url('images/back2.png');  /* æ–°çš„èƒŒæ™¯å›¾ */
  background-size: cover;
  background-position: center;
  display: flex;
  align-items: center;
  justify-content: center;
  color: white;
  font-size: 32px;
">
    <!-- <p style="font-size: 15px; text-align: center; "> 
      When everything that can be removed from ourself is removed, 
      then what remain is what we essentailly are.
    </p> 
    <br>

    <p style="font-size: 15px; text-align: center; "> Â© 2025 Qianqian Jin. All rights reserved.</p>
 -->


 <div style="text-align: center; padding: 20px; background-color: transparent;">
  <p style="font-size: 15px; margin: 0 0 10px 0;">
    When everything that can be removed from ourself is removed,
    then what remain is what we essentially are.
  </p>

  <p style="font-size: 15px; margin: 10px 0 0 0; text-align: center;">
    Â© 2025 Qianqian Jin. All rights reserved.
  </p>
</div>


  </div>



</body>
</html>